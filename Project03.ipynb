{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd04980a42a182309b1db340bd3ce064435eaba3d4abc1dd6e57dbb6df8fa77b905",
   "display_name": "Python 3.8.8 64-bit ('pytorch_x86': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ECE 763 Project 03"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.architecture as model\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn"
   ]
  },
  {
   "source": [
    "## Step 1 Data Preprocessing \n",
    "Data Normalization + Data Augmentation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Step 2: Chosse the arquitecture\n",
    "Here we are using a vanilla CNN inspired in the AlexNet arquitecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model summary:\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 16, 46, 46]           1,216\n       BatchNorm2d-2           [-1, 16, 46, 46]              32\n              ReLU-3           [-1, 16, 46, 46]               0\n         MaxPool2d-4           [-1, 16, 23, 23]               0\n            Conv2d-5           [-1, 32, 11, 11]          86,560\n       BatchNorm2d-6           [-1, 32, 11, 11]              64\n              ReLU-7           [-1, 32, 11, 11]               0\n         MaxPool2d-8             [-1, 32, 5, 5]               0\n            Linear-9                  [-1, 256]         205,056\n             ReLU-10                  [-1, 256]               0\n           Linear-11                   [-1, 32]           8,224\n             ReLU-12                   [-1, 32]               0\n           Linear-13                    [-1, 2]              66\n================================================================\nTotal params: 301,218\nTrainable params: 301,218\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.03\nForward/backward pass size (MB): 0.94\nParams size (MB): 1.15\nEstimated Total Size (MB): 2.12\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "image_res = 50\n",
    "net = model.CNN(image_res)\n",
    "print('Model summary:')\n",
    "summary(net, input_size=(3, image_res, image_res))"
   ]
  },
  {
   "source": [
    "## Step 3: Check the loss is reasonable"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Disable regularization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  1 -> train_loss: 0.20934, train_acc: 0.91500 | val_loss: 0.26118, val_acc: 0.89500 | lr: 0.01000\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 1 --l2 0.0"
   ]
  },
  {
   "source": [
    "Crank up regularization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  1 -> train_loss: 0.64770, train_acc: 0.55300 | val_loss: 0.69301, val_acc: 0.50000 | lr: 0.01000\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 1 --l2 10"
   ]
  },
  {
   "source": [
    "## Step 4: Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Make sure you can overfit a very small portion of the training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  1 -> train_loss: 0.45837, train_acc: 0.82000 | val_loss: 0.23575, val_acc: 0.95000 | lr: 0.01000\n",
      "Epoch  2 -> train_loss: 0.30061, train_acc: 0.87000 | val_loss: 0.22115, val_acc: 1.00000 | lr: 0.01000\n",
      "Epoch  3 -> train_loss: 0.22257, train_acc: 0.98000 | val_loss: 0.13873, val_acc: 1.00000 | lr: 0.01000\n",
      "Epoch  4 -> train_loss: 0.14391, train_acc: 1.00000 | val_loss: 0.07533, val_acc: 1.00000 | lr: 0.01000\n",
      "Epoch  5 -> train_loss: 0.11017, train_acc: 1.00000 | val_loss: 0.06297, val_acc: 1.00000 | lr: 0.01000\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 5 --new_datasets 1 --train 50 --valid 10 --test 10 --l2 0.0 "
   ]
  },
  {
   "source": [
    "Start with small regularization and find the learning rate that makes the loss go down"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  1 -> train_loss: 0.16646, train_acc: 0.93800 | val_loss: 0.39897, val_acc: 0.87500 | lr: 0.01500\n",
      "Epoch  2 -> train_loss: 0.03707, train_acc: 0.99400 | val_loss: 0.14799, val_acc: 0.97000 | lr: 0.01500\n",
      "Epoch  3 -> train_loss: 0.02051, train_acc: 0.99800 | val_loss: 0.17507, val_acc: 0.94000 | lr: 0.01500\n",
      "Epoch  4 -> train_loss: 0.01043, train_acc: 1.00000 | val_loss: 0.12577, val_acc: 0.96000 | lr: 0.01500\n",
      "Epoch  5 -> train_loss: 0.00849, train_acc: 1.00000 | val_loss: 0.18480, val_acc: 0.94000 | lr: 0.01500\n",
      "Epoch  6 -> train_loss: 0.00998, train_acc: 0.99800 | val_loss: 0.10747, val_acc: 0.97000 | lr: 0.01500\n",
      "Epoch  7 -> train_loss: 0.00505, train_acc: 1.00000 | val_loss: 0.12323, val_acc: 0.97000 | lr: 0.01500\n",
      "Epoch  8 -> train_loss: 0.00407, train_acc: 1.00000 | val_loss: 0.12404, val_acc: 0.97000 | lr: 0.01500\n",
      "Epoch  9 -> train_loss: 0.00364, train_acc: 1.00000 | val_loss: 0.12448, val_acc: 0.97000 | lr: 0.01500\n",
      "Epoch 10 -> train_loss: 0.00316, train_acc: 1.00000 | val_loss: 0.12220, val_acc: 0.97000 | lr: 0.01500\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 10 --new_datasets 1 --train 500 --valid 100 --test 100 --lr 0.015 --l2 0.01"
   ]
  },
  {
   "source": [
    "## Step 5: Hyperparameter Optimization "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training samples: \t1000\n",
      "Validation samples: \t200\n",
      "Device to use is cpu\n",
      "Model summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 46, 46]           1,216\n",
      "       BatchNorm2d-2           [-1, 16, 46, 46]              32\n",
      "              ReLU-3           [-1, 16, 46, 46]               0\n",
      "         MaxPool2d-4           [-1, 16, 23, 23]               0\n",
      "            Conv2d-5           [-1, 32, 11, 11]          86,560\n",
      "       BatchNorm2d-6           [-1, 32, 11, 11]              64\n",
      "              ReLU-7           [-1, 32, 11, 11]               0\n",
      "         MaxPool2d-8             [-1, 32, 5, 5]               0\n",
      "            Linear-9                  [-1, 256]         205,056\n",
      "             ReLU-10                  [-1, 256]               0\n",
      "           Linear-11                   [-1, 32]           8,224\n",
      "             ReLU-12                   [-1, 32]               0\n",
      "           Linear-13                    [-1, 2]              66\n",
      "================================================================\n",
      "Total params: 301,218\n",
      "Trainable params: 301,218\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.94\n",
      "Params size (MB): 1.15\n",
      "Estimated Total Size (MB): 2.12\n",
      "----------------------------------------------------------------\n",
      "Epoch  1 -> train_loss: 0.15623, train_acc: 0.94200 | val_loss: 0.07676, val_acc: 0.98000 | lr: 0.01350\n",
      "Epoch  2 -> train_loss: 0.03428, train_acc: 0.98600 | val_loss: 0.08175, val_acc: 0.98500 | lr: 0.01215\n",
      "Epoch  3 -> train_loss: 0.01757, train_acc: 0.99600 | val_loss: 0.07557, val_acc: 0.98000 | lr: 0.01094\n",
      "Epoch  4 -> train_loss: 0.00961, train_acc: 0.99800 | val_loss: 0.07905, val_acc: 0.98500 | lr: 0.00984\n",
      "Epoch  5 -> train_loss: 0.00815, train_acc: 0.99800 | val_loss: 0.05124, val_acc: 0.98500 | lr: 0.00886\n",
      "Epoch  6 -> train_loss: 0.00292, train_acc: 1.00000 | val_loss: 0.06214, val_acc: 0.98500 | lr: 0.00797\n",
      "Epoch  7 -> train_loss: 0.00200, train_acc: 1.00000 | val_loss: 0.07224, val_acc: 0.97500 | lr: 0.00717\n",
      "Epoch  8 -> train_loss: 0.00213, train_acc: 1.00000 | val_loss: 0.06387, val_acc: 0.98500 | lr: 0.00646\n",
      "Epoch  9 -> train_loss: 0.00226, train_acc: 1.00000 | val_loss: 0.06437, val_acc: 0.98500 | lr: 0.00581\n",
      "Epoch 10 -> train_loss: 0.00238, train_acc: 1.00000 | val_loss: 0.06240, val_acc: 0.98500 | lr: 0.00523\n",
      "Training complete!\n",
      "\n",
      "Test samples: \t200\n",
      "Accuracy in test set: 99.000%\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       100\n",
      "           1       0.98      1.00      0.99       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.99      0.99      0.99       200\n",
      "weighted avg       0.99      0.99      0.99       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 10 --lr 0.015 --l2 0.01 --momentum 0.9 --lr_decay_rate 0.1 --verbose 3 --suffix hyper"
   ]
  }
 ]
}